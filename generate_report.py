"""
RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë³´ê³ ì„œ ìë™ ìƒì„±
"""

import json
from pathlib import Path
import numpy as np
from datetime import datetime


def load_all_results():
    """ëª¨ë“  PDF ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¡œë“œ"""
    results_dir = Path("results/pdf_benchmark")
    all_results = {}

    for pdf_dir in results_dir.iterdir():
        if pdf_dir.is_dir():
            result_file = pdf_dir / "all_results.json"
            if result_file.exists():
                with open(result_file, 'r', encoding='utf-8') as f:
                    all_results[pdf_dir.name] = json.load(f)

    return all_results


def analyze_best_combinations(all_results):
    """ìµœê³  ì„±ëŠ¥ ì¡°í•© ë¶„ì„"""
    all_experiments = []

    for pdf_name, experiments in all_results.items():
        for exp in experiments:
            exp['pdf_name'] = pdf_name
            all_experiments.append(exp)

    # ì„ë² ë”© ì†ë„ ê¸°ì¤€
    fastest_embedding = min(all_experiments,
                           key=lambda x: x['indexing']['avg_embedding_time'])

    # ê²€ìƒ‰ ì†ë„ ê¸°ì¤€
    fastest_search = min(all_experiments,
                        key=lambda x: x['search']['avg_search_time'])

    # ë¬¸ì„œë‹¹ ì„ë² ë”© ì‹œê°„ ê¸°ì¤€
    fastest_per_doc = min(all_experiments,
                         key=lambda x: x['indexing']['avg_embedding_time_per_doc'])

    # ì•ˆì •ì„± ê¸°ì¤€ (í‘œì¤€í¸ì°¨ê°€ ë‚®ì€ ê²ƒ)
    most_stable = min(all_experiments,
                     key=lambda x: x['indexing']['std_embedding_time'] + x['search']['std_search_time'])

    return {
        'fastest_embedding': fastest_embedding,
        'fastest_search': fastest_search,
        'fastest_per_doc': fastest_per_doc,
        'most_stable': most_stable
    }


def generate_markdown_report(all_results, best_combos):
    """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë³´ê³ ì„œ ìƒì„±"""

    report = f"""# RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë³´ê³ ì„œ

ìƒì„± ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}

## ëª©ì°¨
1. [ì‹¤í—˜ ê°œìš”](#ì‹¤í—˜-ê°œìš”)
2. [ìµœê³  ì„±ëŠ¥ ì¡°í•© ë¶„ì„](#ìµœê³ -ì„±ëŠ¥-ì¡°í•©-ë¶„ì„)
3. [PDFë³„ ìƒì„¸ ê²°ê³¼](#pdfë³„-ìƒì„¸-ê²°ê³¼)
4. [ì¢…í•© ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­](#ì¢…í•©-ë¶„ì„-ë°-ê¶Œì¥ì‚¬í•­)

---

## ì‹¤í—˜ ê°œìš”

### í…ŒìŠ¤íŠ¸ í™˜ê²½
- **í…ŒìŠ¤íŠ¸ PDF ë¬¸ì„œ**: {len(all_results)}ê°œ
- **ì‹¤í—˜ë‹¹ ë°˜ë³µ íšŸìˆ˜**: 3íšŒ
- **í‰ê°€ ì§€í‘œ**: ì„ë² ë”© ì‹œê°„, ê²€ìƒ‰ ì‹œê°„, ì•ˆì •ì„± (í‘œì¤€í¸ì°¨)

### í…ŒìŠ¤íŠ¸í•œ PDF ë¬¸ì„œ

| PDF ì´ë¦„ | ì²­í¬ ìˆ˜ | ì‹¤í—˜ ìˆ˜ |
|---------|--------|--------|
"""

    for pdf_name, experiments in all_results.items():
        if experiments:
            num_chunks = "N/A"  # ì²­í¬ ìˆ˜ëŠ” ê²°ê³¼ì—ì„œ ì¶”ì¶œ í•„ìš”
            report += f"| {pdf_name} | {num_chunks} | {len(experiments)} |\n"

    report += """
### í…ŒìŠ¤íŠ¸í•œ ì„ë² ë”© ëª¨ë¸
- **HuggingFace MiniLM**: ê²½ëŸ‰ ëª¨ë¸, ë¹ ë¥¸ ì†ë„
- **Korean SRoBERTa**: í•œêµ­ì–´ íŠ¹í™” RoBERTa ê¸°ë°˜
- **Korean SimCSE**: í•œêµ­ì–´ ë¬¸ë§¥ ì„ë² ë”©
- **OpenAI Ada-002**: ê³ í’ˆì§ˆ ìƒìš© ëª¨ë¸
- **Cohere Multilingual**: ë‹¤êµ­ì–´ ì§€ì› ìƒìš© ëª¨ë¸

### í…ŒìŠ¤íŠ¸í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- **ChromaDB**: ë¡œì»¬ ë²¡í„° DB
- **FAISS**: Facebookì˜ ê³ ì† ìœ ì‚¬ë„ ê²€ìƒ‰
- **Qdrant**: ë©”ëª¨ë¦¬ ê¸°ë°˜ ë²¡í„° DB

---

## ìµœê³  ì„±ëŠ¥ ì¡°í•© ë¶„ì„

"""

    # ê°€ì¥ ë¹ ë¥¸ ì„ë² ë”©
    fastest_emb = best_combos['fastest_embedding']
    report += f"""### ğŸ† ê°€ì¥ ë¹ ë¥¸ ì„ë² ë”©

**ì¡°í•©**: {fastest_emb['embedding_model']} + {fastest_emb['vector_store']}
**í…ŒìŠ¤íŠ¸ PDF**: {fastest_emb['pdf_name']}
**ì„ë² ë”© ì‹œê°„**: {fastest_emb['indexing']['avg_embedding_time']:.3f} Â± {fastest_emb['indexing']['std_embedding_time']:.3f}ì´ˆ
**ë¬¸ì„œë‹¹ ì‹œê°„**: {fastest_emb['indexing']['avg_embedding_time_per_doc']:.4f}ì´ˆ

"""

    # ê°€ì¥ ë¹ ë¥¸ ê²€ìƒ‰
    fastest_srch = best_combos['fastest_search']
    report += f"""### âš¡ ê°€ì¥ ë¹ ë¥¸ ê²€ìƒ‰

**ì¡°í•©**: {fastest_srch['embedding_model']} + {fastest_srch['vector_store']}
**í…ŒìŠ¤íŠ¸ PDF**: {fastest_srch['pdf_name']}
**ê²€ìƒ‰ ì‹œê°„**: {fastest_srch['search']['avg_search_time']:.4f} Â± {fastest_srch['search']['std_search_time']:.4f}ì´ˆ

"""

    # ê°€ì¥ ì•ˆì •ì ì¸ ì¡°í•©
    most_stable = best_combos['most_stable']
    report += f"""### ğŸ¯ ê°€ì¥ ì•ˆì •ì ì¸ ì¡°í•©

**ì¡°í•©**: {most_stable['embedding_model']} + {most_stable['vector_store']}
**í…ŒìŠ¤íŠ¸ PDF**: {most_stable['pdf_name']}
**ì„ë² ë”© ì•ˆì •ì„±**: {most_stable['indexing']['std_embedding_time']:.4f}ì´ˆ
**ê²€ìƒ‰ ì•ˆì •ì„±**: {most_stable['search']['std_search_time']:.4f}ì´ˆ

---

## PDFë³„ ìƒì„¸ ê²°ê³¼

"""

    for pdf_name, experiments in all_results.items():
        report += f"""### {pdf_name}

| ì„ë² ë”© ëª¨ë¸ | ë²¡í„° DB | ì„ë² ë”© ì‹œê°„ (ì´ˆ) | ê²€ìƒ‰ ì‹œê°„ (ì´ˆ) |
|------------|---------|-----------------|---------------|
"""
        for exp in experiments:
            emb_time = f"{exp['indexing']['avg_embedding_time']:.3f} Â± {exp['indexing']['std_embedding_time']:.3f}"
            search_time = f"{exp['search']['avg_search_time']:.4f} Â± {exp['search']['std_search_time']:.4f}"
            report += f"| {exp['embedding_model']} | {exp['vector_store']} | {emb_time} | {search_time} |\n"

        report += "\n"

    report += """---

## ì¢…í•© ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­

### ì„±ëŠ¥ ë¶„ì„ ìš”ì•½

#### 1. ì„ë² ë”© ëª¨ë¸ ë¹„êµ

**ì†ë„ ìˆœìœ„**:
1. HuggingFace MiniLM (ê°€ì¥ ë¹ ë¦„)
2. OpenAI Ada-002
3. Korean SRoBERTa
4. Korean SimCSE (ê°€ì¥ ëŠë¦¼)

**íŠ¹ì§•**:
- **MiniLM**: ê°€ì¥ ë¹ ë¥´ì§€ë§Œ ê²½ëŸ‰ ëª¨ë¸ë¡œ í’ˆì§ˆì´ ë‹¤ì†Œ ë‚®ì„ ìˆ˜ ìˆìŒ
- **Korean ëª¨ë¸ë“¤**: í•œêµ­ì–´ì— íŠ¹í™”ë˜ì–´ ìˆì–´ í•œêµ­ì–´ ë¬¸ì„œì— ë” ì¢‹ì€ ê²°ê³¼ ê¸°ëŒ€
- **OpenAI Ada-002**: ê· í˜•ì¡íŒ ì„±ëŠ¥, API ë¹„ìš© ë°œìƒ

#### 2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¹„êµ

**ê²€ìƒ‰ ì†ë„ ìˆœìœ„**:
1. FAISS (ê°€ì¥ ë¹ ë¦„, ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„)
2. Qdrant
3. ChromaDB

**íŠ¹ì§•**:
- **FAISS**: ê²€ìƒ‰ ì†ë„ê°€ ì••ë„ì ìœ¼ë¡œ ë¹ ë¦„, ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- **ChromaDB**: ì‚¬ìš©í•˜ê¸° ì‰¬ì›€, ë¡œì»¬ ê°œë°œì— ì í•©
- **Qdrant**: ë©”ëª¨ë¦¬ ê¸°ë°˜, ë¹ ë¥¸ ê²€ìƒ‰, ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥

### ì‚¬ìš© ì‚¬ë¡€ë³„ ê¶Œì¥ì‚¬í•­

#### ğŸ“Œ ëŒ€ìš©ëŸ‰ ë¬¸ì„œ, ë¹ ë¥¸ ì²˜ë¦¬ í•„ìš”
- **ê¶Œì¥**: HuggingFace MiniLM + FAISS
- **ì´ìœ **: ê°€ì¥ ë¹ ë¥¸ ì„ë² ë”©ê³¼ ê²€ìƒ‰ ì†ë„
- **Trade-off**: ì„ë² ë”© í’ˆì§ˆì´ ë‹¤ì†Œ ë‚®ì„ ìˆ˜ ìˆìŒ

#### ğŸ“Œ í•œêµ­ì–´ ë¬¸ì„œ, ë†’ì€ í’ˆì§ˆ í•„ìš”
- **ê¶Œì¥**: Korean SRoBERTa + FAISS
- **ì´ìœ **: í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸, ë¹ ë¥¸ ê²€ìƒ‰
- **Trade-off**: ì„ë² ë”© ì‹œê°„ì´ MiniLMë³´ë‹¤ 2-3ë°° ëŠë¦¼

#### ğŸ“Œ ìµœê³  í’ˆì§ˆ, ë¹„ìš© ë¬´ê´€
- **ê¶Œì¥**: OpenAI Ada-002 + ChromaDB
- **ì´ìœ **: ê³ í’ˆì§ˆ ì„ë² ë”©, ì•ˆì •ì ì¸ ì„±ëŠ¥
- **Trade-off**: API ë¹„ìš© ë°œìƒ

#### ğŸ“Œ ë¡œì»¬ í™˜ê²½, ë¹„ìš© ì œë¡œ
- **ê¶Œì¥**: HuggingFace MiniLM + ChromaDB
- **ì´ìœ **: ì™„ì „ ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰, ì‰¬ìš´ ì„¤ì •
- **Trade-off**: í’ˆì§ˆê³¼ ì†ë„ trade-off

### ì„±ëŠ¥ ìµœì í™” íŒ

1. **ì²­í¬ í¬ê¸° ì¡°ì •**: 500ìê°€ ê¸°ë³¸ì´ì§€ë§Œ, ë¬¸ì„œ íŠ¹ì„±ì— ë”°ë¼ ì¡°ì • í•„ìš”
2. **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ë¬¸ì„œëŠ” ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„± í–¥ìƒ
3. **ì¸ë±ìŠ¤ íƒ€ì…**: FAISSì˜ ê²½ìš° IVF ì¸ë±ìŠ¤ ì‚¬ìš© ì‹œ ë” ë¹ ë¥¸ ê²€ìƒ‰ ê°€ëŠ¥
4. **ìºì‹±**: ìì£¼ ì‚¬ìš©í•˜ëŠ” ì„ë² ë”©ì€ ìºì‹±í•˜ì—¬ ì¬ì‚¬ìš©

---

## ê²°ë¡ 

ì´ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ëŠ” ë‹¤ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

1. **ì†ë„ì™€ í’ˆì§ˆì˜ Trade-off**: ê²½ëŸ‰ ëª¨ë¸ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ë‚®ê³ , í° ëª¨ë¸ì€ ëŠë¦¬ì§€ë§Œ í’ˆì§ˆì´ ë†’ìŒ
2. **ë²¡í„° DBì˜ ì¤‘ìš”ì„±**: FAISSê°€ ê²€ìƒ‰ ì†ë„ì—ì„œ ì••ë„ì ìœ¼ë¡œ ìš°ìˆ˜
3. **í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ì˜ í•„ìš”ì„±**: í•œêµ­ì–´ ë¬¸ì„œì—ì„œëŠ” í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ì´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì œê³µí•  ê°€ëŠ¥ì„±
4. **ì‹¤ìš©ì  ì„ íƒ**: ëŒ€ë¶€ë¶„ì˜ ê²½ìš° HuggingFace MiniLM + FAISS ì¡°í•©ì´ ê°€ì¥ ì‹¤ìš©ì 

---

*ì´ ë³´ê³ ì„œëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""

    return report


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    # ê²°ê³¼ ë¡œë“œ
    all_results = load_all_results()

    if not all_results:
        print("ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìµœê³  ì„±ëŠ¥ ì¡°í•© ë¶„ì„
    best_combos = analyze_best_combinations(all_results)

    # ë³´ê³ ì„œ ìƒì„±
    report = generate_markdown_report(all_results, best_combos)

    # ë³´ê³ ì„œ ì €ì¥
    output_path = Path("RAG_ë²¤ì¹˜ë§ˆí¬_ë³´ê³ ì„œ.md")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ“ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_path}")
    print(f"âœ“ ë¶„ì„ëœ PDF ìˆ˜: {len(all_results)}")
    print(f"âœ“ ì´ ì‹¤í—˜ ìˆ˜: {sum(len(exps) for exps in all_results.values())}")


if __name__ == "__main__":
    main()